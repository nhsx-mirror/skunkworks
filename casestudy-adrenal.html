<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@NHSuk"/><meta name="twitter:creator" content="@NHSuk"/><meta property="og:url" content="https://nhsx.github.io/skunkworks/"/><meta property="og:image" content="https://nhsx.github.io/skunkworks/social-cover.jpg"/><meta property="og:image:alt" content="NHS AI Lab Skunkworks Social Cover"/><meta property="og:image:type" content="image/jpeg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><title>Using deep learning to detect adrenal lesions in CT scans | NHS AI Lab Skunkworks</title><meta name="robots" content="index,follow"/><meta name="description" content="Augmenting the detection of adrenal incidentalomas in patients’ CT scans."/><meta property="og:title" content="Using deep learning to detect adrenal lesions in CT scans | NHS AI Lab Skunkworks"/><meta property="og:description" content="Augmenting the detection of adrenal incidentalomas in patients’ CT scans."/><meta name="next-head-count" content="16"/><link rel="icon" href="/favicon.ico"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/skunkworks/_next/static/css/1e24fbca24494117.css" as="style"/><link rel="stylesheet" href="/skunkworks/_next/static/css/1e24fbca24494117.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/skunkworks/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/skunkworks/_next/static/chunks/webpack-382465b464c37bb5.js" defer=""></script><script src="/skunkworks/_next/static/chunks/framework-5f4595e5518b5600.js" defer=""></script><script src="/skunkworks/_next/static/chunks/main-a05df26ae4493c52.js" defer=""></script><script src="/skunkworks/_next/static/chunks/pages/_app-3fabb4cbd231f59d.js" defer=""></script><script src="/skunkworks/_next/static/chunks/622-6b0ef3ffcb46ab6b.js" defer=""></script><script src="/skunkworks/_next/static/chunks/234-830443fac4b3a699.js" defer=""></script><script src="/skunkworks/_next/static/chunks/pages/%5Bslug%5D-7385ec9ab8515315.js" defer=""></script><script src="/skunkworks/_next/static/S7_uiDiuluxHyjQ4xYDZ1/_buildManifest.js" defer=""></script><script src="/skunkworks/_next/static/S7_uiDiuluxHyjQ4xYDZ1/_ssgManifest.js" defer=""></script><script src="/skunkworks/_next/static/S7_uiDiuluxHyjQ4xYDZ1/_middlewareManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Inter:wght@200;300;400;500;600;700&display=swap">@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuDyfMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuOKfMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuLyfMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuI6fMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuGKYMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuFuYMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02AF,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02AF,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02AF,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02AF,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02AF,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02AF,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next" data-reactroot=""><div class="antialiased"><div class="min-h-full"><nav class="bg-blue-500"><div class="mx-auto px-4 sm:px-6 lg:px-8 max-w-6xl"><div class="flex justify-between py-6"><div class="flex"><a class="flex flex-col space-y-6 md:space-y-4 lg:space-y-0 lg:flex-row lg:items-center lg:space-x-2 flex-shrink-0 text-white" href="/skunkworks"><span><img class="h-10 w-auto" src="/skunkworks/nhs-logo-inverted.svg" alt="NHS"/></span><span class="text-sm lg:text-lg">AI Lab Skunkworks</span></a></div><div class="hidden md:flex"><div class="flex-1 flex items-center space-x-6"><form action="/skunkworks/search" method="GET" class="flex-1 justify-stretch relative flex"><div class="flex-1"><input type="text" name="q" placeholder="Search" class="w-full border-2 border-transparent focus:ring-nhsuk-focus focus:ring-4 rounded-tl rounded-bl sm:text-sm" value=""/></div><div><button type="submit" class="w-full h-full flex-1 bg-gray-50 rounded-tr rounded-br px-3 text-blue-500 focus:bg-nhsuk-yellow focus:text-black "><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="w-6 h-6"><path fill-rule="evenodd" d="M8 4a4 4 0 100 8 4 4 0 000-8zM2 8a6 6 0 1110.89 3.476l4.817 4.817a1 1 0 01-1.414 1.414l-4.816-4.816A6 6 0 012 8z" clip-rule="evenodd"></path></svg></button></div></form><a target="_BLANK" class="rounded-full" href="https://github.com/nhsx/skunkworks"><svg class="w-10 h-10 flex-shrink-0 text-white" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 17 16" fill="none"><g clip-path="url(githublogo)"><path fill="currentColor" fill-rule="evenodd" d="M8.18391.249268C3.82241.249268.253906 3.81777.253906 8.17927c0 3.46933 2.279874 6.44313 5.451874 7.53353.3965.0991.49563-.1983.49563-.3965v-1.3878c-2.18075.4956-2.67638-.9912-2.67638-.9912-.3965-.8922-.89212-1.1895-.89212-1.1895-.69388-.4957.09912-.4957.09912-.4957.793.0992 1.1895.793 1.1895.793.69388 1.2887 1.88338.8922 2.27988.6939.09912-.4956.29737-.8921.49562-1.0904-1.78425-.1982-3.5685-.8921-3.5685-3.96496 0-.89212.29738-1.586.793-2.08162-.09912-.19825-.3965-.99125.09913-2.08163 0 0 .69387-.19825 2.18075.793.59475-.19825 1.28862-.29737 1.9825-.29737.69387 0 1.38775.09912 1.98249.29737 1.4869-.99125 2.1808-.793 2.1808-.793.3965 1.09038.1982 1.88338.0991 2.08163.4956.59475.793 1.28862.793 2.08162 0 3.07286-1.8834 3.66766-3.66764 3.86586.29737.3965.59474.8921.59474 1.586v2.1808c0 .1982.0991.4956.5948.3965 3.172-1.0904 5.4518-4.0642 5.4518-7.53353-.0991-4.3615-3.6676-7.930002-8.02909-7.930002z" clip-rule="evenodd" class="jsx-1651122719"></path></g><defs><clipPath id="githublogo"><path fill="transparent" d="M0 0h15.86v15.86H0z" transform="translate(.253906 .0493164)"></path></clipPath></defs></svg></a></div></div><div class="-mr-2 flex items-start md:hidden"><button class="bg-white inline-flex items-center justify-center p-2 text-nhsuk-text hover:bg-gray-100 focus:bg-nhsuk-yellow focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-nhsuk-yellow" id="headlessui-disclosure-button-undefined" type="button" aria-expanded="false"><span class="sr-only">Open main menu</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" aria-hidden="true" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div><div class="hidden md:block"><div class="border-t border-white border-opacity-20"><nav class="flex flex-col space-y-2 md:space-y-0 md:flex-row md:space-x-6"><a class="border-transparent group flex items-center px-4 py-4 border-l-4 md:border-l-0 text-white hover:underline text-base focus:bg-nhsuk-yellow focus:text-black focus:border-black md:focus:border-b-4 md:focus:pb-3" href="/skunkworks">Overview</a><a class="border-transparent group flex items-center px-4 py-4 border-l-4 md:border-l-0 text-white hover:underline text-base focus:bg-nhsuk-yellow focus:text-black focus:border-black md:focus:border-b-4 md:focus:pb-3" href="/skunkworks/data-lens">Projects</a><a class="border-transparent group flex items-center px-4 py-4 border-l-4 md:border-l-0 text-white hover:underline text-base focus:bg-nhsuk-yellow focus:text-black focus:border-black md:focus:border-b-4 md:focus:pb-3" href="/skunkworks/ai-deep-dive">Playbooks</a><a class="border-transparent group flex items-center px-4 py-4 border-l-4 md:border-l-0 text-white hover:underline text-base focus:bg-nhsuk-yellow focus:text-black focus:border-black md:focus:border-b-4 md:focus:pb-3" href="/skunkworks/casestudy-parkinsons-detection">Case Study Archive</a><a class="border-transparent group flex items-center px-4 py-4 border-l-4 md:border-l-0 text-white hover:underline text-base focus:bg-nhsuk-yellow focus:text-black focus:border-black md:focus:border-b-4 md:focus:pb-3" href="/skunkworks/team">Team</a></nav></div></div></div></nav><div class=""><main class="flex-1"><div class="mx-auto px-4 sm:px-6 lg:px-8 max-w-6xl"><div class="flex flex-col py-8 lg:flex-row lg:py-12"><div class="hidden lg:flex relative w-80 flex-shrink-0"><div class="-mt-6"><div class="sticky top-0 pt-6"><div class="flex-grow flex flex-col space-y-8"><div class="space-y-4"><div class="flex items-center space-x-3"><div><div class="bg-blue-500 rounded p-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="w-4 h-4 text-white"><path fill-rule="evenodd" d="M7 2a1 1 0 00-.707 1.707L7 4.414v3.758a1 1 0 01-.293.707l-4 4C.817 14.769 2.156 18 4.828 18h10.343c2.673 0 4.012-3.231 2.122-5.121l-4-4A1 1 0 0113 8.172V4.414l.707-.707A1 1 0 0013 2H7zm2 6.172V4h2v4.172a3 3 0 00.879 2.12l1.027 1.028a4 4 0 00-2.171.102l-.47.156a4 4 0 01-2.53 0l-.563-.187a1.993 1.993 0 00-.114-.035l1.063-1.063A3 3 0 009 8.172z" clip-rule="evenodd"></path></svg></div></div><div><p class="font-semibold text-gray-400 uppercase tracking-wider text-xs">Projects</p></div></div><nav class="mb-4 space-y-1 border-l border-gray-200 ml-3"><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/data-lens">Data Lens</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/long-stay">Long Stayer Risk Stratification</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/ct-alignment">CT Alignment and Lesion Detection</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/bed-allocation">Bed allocation</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/ai-dictionary">AI Dictionary</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/synthetic-data-pipeline">Synthetic Data</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/nursing-placement-optimisation">Nursing Placement Schedule Optimisation</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/long-stay-baseline">Long Stayer Risk Stratification baseline</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/ambulance-delay-predictor">Ambulance Handover Delay Predictor</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/parkinsons-detection">Parkinson&#x27;s Disease Pathology Prediction</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/renal-health-prediction">Renal Health Prediction</a></nav></div><div class="space-y-4"><div class="flex items-center space-x-3"><div><div class="bg-blue-500 rounded p-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="w-4 h-4 text-white"><path d="M9 4.804A7.968 7.968 0 005.5 4c-1.255 0-2.443.29-3.5.804v10A7.969 7.969 0 015.5 14c1.669 0 3.218.51 4.5 1.385A7.962 7.962 0 0114.5 14c1.255 0 2.443.29 3.5.804v-10A7.968 7.968 0 0014.5 4c-1.255 0-2.443.29-3.5.804V12a1 1 0 11-2 0V4.804z"></path></svg></div></div><div><p class="font-semibold text-gray-400 uppercase tracking-wider text-xs">Playbooks</p></div></div><nav class="mb-4 space-y-1 border-l border-gray-200 ml-3"><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/ai-deep-dive">AI Deep Dive</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/project-flow">AI Prototype Project Flow</a></nav></div><div class="space-y-4"><div class="flex items-center space-x-3"><div><div class="bg-blue-500 rounded p-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="w-4 h-4 text-white"><path d="M9 4.804A7.968 7.968 0 005.5 4c-1.255 0-2.443.29-3.5.804v10A7.969 7.969 0 015.5 14c1.669 0 3.218.51 4.5 1.385A7.962 7.962 0 0114.5 14c1.255 0 2.443.29 3.5.804v-10A7.968 7.968 0 0014.5 4c-1.255 0-2.443.29-3.5.804V12a1 1 0 11-2 0V4.804z"></path></svg></div></div><div><p class="font-semibold text-gray-400 uppercase tracking-wider text-xs">Case Study Archive</p></div></div><nav class="mb-4 space-y-1 border-l border-gray-200 ml-3"><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/casestudy-parkinsons-detection">Parkinson&#x27;s Disease Pathology Prediction</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/casestudy-nursing-placement-optimisation">Nursing Placement Schedule Optimisation</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/casestudy-synthetic-data-pipeline">Synthetic Data</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/casestudy-bed-allocation">Bed allocation</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/casestudy-ct-alignment">CT Alignment and Lesion Detection</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/casestudy-data-lens">Data Lens</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/casestudy-nhs-resolution">Negligence Claims Prediction</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/casestudy-long-stay">Long Stayer Risk Stratification</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/casestudy-opensafely">Open Safely</a><a class="underline font-medium -ml-1 pl-7 text-blue-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/casestudy-adrenal"><div class="flex absolute -left-1 top-1/2 -mt-2 rounded-full border w-4 h-4 bg-white p-px"><div class="rounded-full bg-blue-500 flex-1"></div></div>Adrenal Incidentalomas Detection</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/casestudy-ai-deep-dive">AI Deep Dive at UHS</a></nav></div><div class="space-y-4"><div class="flex items-center space-x-3"><div><div class="bg-blue-500 rounded p-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="w-4 h-4 text-white"><path d="M9 6a3 3 0 11-6 0 3 3 0 016 0zM17 6a3 3 0 11-6 0 3 3 0 016 0zM12.93 17c.046-.327.07-.66.07-1a6.97 6.97 0 00-1.5-4.33A5 5 0 0119 16v1h-6.07zM6 11a5 5 0 015 5v1H1v-1a5 5 0 015-5z"></path></svg></div></div><div><p class="font-semibold text-gray-400 uppercase tracking-wider text-xs">Team</p></div></div><nav class="mb-4 space-y-1 border-l border-gray-200 ml-3"><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/skunkworks/team">Team</a></nav></div></div></div></div></div><div class="lg:hidden flex flex-col mb-8"><button class="bg-gray-100 flex justify-center items-center p-4 text-gray-500 underline" id="headlessui-disclosure-button-undefined" type="button" aria-expanded="false">Show menu</button></div><div class="flex-1 space-y-10"><div class="prose max-w-none"><h1>Using deep learning to detect adrenal lesions in CT scans</h1><blockquote><p>Augmenting the detection of adrenal incidentalomas in patients’ CT scans.</p></blockquote><div class=""><div class="flex gap-2"><div class="px-3 py-1 bg-gray-100 text-gray-500 text-sm font-medium rounded">vision AI</div><div class="px-3 py-1 bg-gray-100 text-gray-500 text-sm font-medium rounded">classification</div><div class="px-3 py-1 bg-gray-100 text-gray-500 text-sm font-medium rounded">deep learning</div><div class="px-3 py-1 bg-gray-100 text-gray-500 text-sm font-medium rounded">pathology</div><div class="px-3 py-1 bg-gray-100 text-gray-500 text-sm font-medium rounded">neural networks</div></div></div>
<h2>Info</h2>
<p>This is a backup of the case study published <a href="https://transform.england.nhs.uk/ai-lab/explore-all-resources/develop-ai/using-deep-learning-to-detect-adrenal-lesions-in-ct-scans/">here</a> on the NHS England Transformation Directorate website.</p>
<h2>Case Study</h2>
<p>Many cases of adrenal lesions, known as adrenal incidentalomas, are discovered incidentally on CT scans performed for other medical conditions. These lesions can be malignant, and so early detection is crucial for patients to receive the correct treatment and allow the public health system to target resources efficiently. Traditionally, the detection of adrenal lesions on CT scans relies on manual analysis by radiologists, which can be time-consuming and unsystematic.</p>
<p><strong>The challenge</strong><br/>
<!-- -->Can applying AI and deep learning augment the detection of adrenal incidentalomas in patients’ CT scans?</p>
<h3>Overview</h3>
<p>Autopsy studies reveal a statistic that as many as 6% of all natural deaths displayed a previously undiagnosed adrenal lesion. Such lesions are also found incidentally (and are therefore referred to as adrenal incidentalomas) in approximately 1% of chest or abdominal CT scans. These lesions affect approximately 50,000 patients annually in the United Kingdom, with significant impact on patient health, including 10% to 15% of cases of excess hormone production, or 1% to 5% of cases of cancer.</p>
<p>It is a significant challenge for the health care system to, in a standardised way, promptly reassure the majority of patients, who have no abnormalities, whilst effectively focusing on those with hormone excess or cancers. Issues include over-reporting (false positives), causing patient anxiety and unnecessary investigations (wasting resources of the health care system), and under-reporting (missed cases), with potentially fatal outcomes. This has major impacts on patient well-being and clinical outcomes, as well as cost-effectiveness.</p>
<p>The main aim of this study was to examine whether or not using Artificial Intelligence (AI) can improve the detection of adrenal incidentalomas in CT scans. Previous studies have suggested that AI has the potential in distinguishing different types of adrenal lesions. In this study, we specifically focused on detecting the presence of any type of adrenal lesion in CT scans. To demonstrate this proof-of-concept, we investigated the potential of applying deep learning techniques to predict the likelihood of a CT abdominal scan presenting as ‘normal’ or ‘abnormal’, the latter implying the presence of an adrenal lesion.</p>
<h3>What we did</h3>
<p>Using the data provided by University Hospitals of North Midlands NHS Trust, we developed a 2.5D deep learning model to perform detection of adrenal lesions in patients’ CT scans (binary classification of normal and abnormal adrenal glands). The entire dataset is completely anonymised and does not contain any personal or identifiable information of patients. The only clinical information taken were the binary labels for adrenal lesions (‘normal’ or ‘abnormal’) for the pseudo-labelled patients and their CT scans.</p>
<h4>2.5D images</h4>
<p>A 2.5D image is a type of image that lies between a typical 2D and 3D image. It can retain some level of 3D features and can potentially be processed as a 2D image by deep learning models. A greyscale 2D image is two dimensional with a size of x × y, where x and y are the length and width of the 2D image. For a greyscale 3D image (e.g., a CT scan), with a size of x × y × n, it can be considered as a combination of a stack of n number of greyscale 2D images. In other words, a CT scan is a 3D image consisting of multiple 2D images layered on top of each other. The size of a 2.5D image is x × y × 3, and it represents a stack of 3 greyscale 2D images.</p>
<p>Typically, an extra dimension of pixel information is required to record and display 2D colour images in electronic systems, such as the three RGB (red, green, and blue) colour channels. This increases the size of a 2D image to x × y × 3, where the 3 represents the three RGB channels. Many commonly used families of 2D deep learning algorithms (e.g., VGG, ResNet, and EfficientNet) have taken colour images into account and have the ability to process images with the extra three channels. Taking the advantage of the fact that pixel volumes have the same size between 2D colour images and 2.5D images, converting our 3 dimensional CT scan data to 2.5D images can allow us to apply 2D deep learning models on our images.</p>
<h4>Why using a 2.5D model</h4>
<p>Due to the intrinsic nature of CT scans (e.g., a high operating cost, limited number of available CT scanners, and patients’ exposure to radiation), the acquisition of a sufficient amount of CT scans for 3D deep learning models training is challenging. In many cases, the performance of 3D deep learning models is limited by the small and non-diversified dataset. Training, validating, and testing the model with a small dataset can lead to many disadvantages, for example, a high risk of overfitting the training-validation set (low prediction ability on an unseen test set), and evaluating the model performance within the ambit of a small number statistic (underrepresented test set results in the test accuracy much lower/higher than the underlying model performance).</p>
<p>To overcome some of the disadvantage of training a 3D deep learning model, we took a 2.5D deep learning model approach in this case study. Training the model using 2.5D images enables our deep learning model to still learn from the 3D features of the CT scans, while increasing the number of training and testing data points in this study. Moreover, we can apply 2D deep learning models to the set of 2.5D images, which allow us to apply transfer learning to train our own model further based on the knowledge learned by other deep learning applications (e.g., ImageNet, and the NHS AI Lab’s National COVID-19 Chest Imaging Database).</p>
<figure><p><img src="images/Flow_of_transfer.width-800.png" alt="Adrenal flow of transfer"/></p></figure>
<h4>Classification of 3D CT scans</h4>
<p>To perform the binary classification on the overal CT scans (instead of a single 2.5D image), the classification results from each individual 2.5D image that make up a CT scan are considered.</p>
<p>To connect the classification prediction results from the 2.5D images to the CT scan, we introduce an operating value for our model to provide the final classification. The CT scans are classified as normal if the number of abnormal 2.5D images is lower than the threshold operating value. For example, if the operating value is defined to be X, a CT scan will be considered as normal if there are more than X of its 2.5D images classified as normal by our model.</p>
<h4>Processing the CT scans to focus on the adrenal glands</h4>
<p>To prepare the CT scans for this case study (region of interest focus on the adrenal grands), we also developed a manual 3D cropping tool for CT scans. This cropping applied to all three dimensions, including a 1D cropping to select the appropriate axial slices and a 2D cropping on each axial slice. The final cropped 3D image covered the whole adrenal gland on both sides with some extra margin on each side.</p>
<figure><p><img src="images/Cropping_process.width-800.png" alt="Adrenal cropping"/></p></figure>
<h3>Outcomes and lessons learned</h3>
<p><a href="https://github.com/nhsx/skunkworks-adrenal-lesions-detection">The resulting code, released as open source on our</a> Github (available to anyone to re-use), enables users to:</p>
<ul>
<li>Process CT scans to focus on the region of interest (e.g., adrenal glands),</li>
<li>Transform 3D CT scans to sets of 2.5D images,</li>
<li>Train a deep learning model with the 2.5D images for adrenal lesion detection (classification: normal vs. abnormal),</li>
<li>Evaluate the trained deep learning model on an independent test set.</li>
</ul>
<p>This proof-of-concept model demonstrates the ability and potential of applying such deep learning techniques in the detection of adrenal lesions on CT scans. It also shows an opportunity to detect adrenal incidentalomas using deep learning.</p>
<blockquote>
<p>An AI solution will allow for lesions to be detected more systematically and flagged for the reporting radiologist. In addition to enhanced patient safety, through minimising missed cases and variability in reporting, this is likely to be a cost-effective solution, saving clinician time.
– Professor Fahmy Hanna, Professor of Endocrinology and Metabolism, Keele Medical School and University Hospitals of North Midlands NHS Trust</p>
</blockquote>
<h3>Who was involved?</h3>
<p>This project was a collaboration between the NHS AI Lab Skunkworks, within the Transformation Directorate at NHS England and NHS Improvement, and University Hospitals of North Midlands NHS Trust.</p></div><div class="flex justify-between items-center"></div></div></div></div></main></div></div><div class="bg-gray-200 text-gray-500 border-t-4 border-blue-500 py-8 md:py-10"><div class="mx-auto px-4 sm:px-6 lg:px-8 max-w-6xl"><div class="space-y-10 sm:space-y-6"><div class="flex flex-col space-y-6 md:space-y-0 md:space-x-10 md:flex-row md:justify-between md:items-start"><div class="space-y-2 md:space-y-0 -ml-4"><a class="block md:inline-block underline px-4 pb-4" href="/skunkworks">Overview</a><a class="block md:inline-block underline px-4 pb-4" href="/skunkworks/data-lens">Projects</a><a class="block md:inline-block underline px-4 pb-4" href="/skunkworks/ai-deep-dive">Playbooks</a><a class="block md:inline-block underline px-4 pb-4" href="/skunkworks/casestudy-parkinsons-detection">Case Study Archive</a><a class="block md:inline-block underline px-4 pb-4" href="/skunkworks/team">Team</a></div><div class="flex-shrink-0">© Copyright 2021-2023 NHS AI Lab</div></div><div class="flex flex-col space-y-3 sm:flex-row sm:items-center sm:space-y-0 sm:space-x-3 text-base"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 483.2 195.7" height="17" width="41" focusable="false"><path fill="currentColor" d="M421.5 142.8V.1l-50.7 32.3v161.1h112.4v-50.7zm-122.3-9.6A47.12 47.12 0 0 1 221 97.8c0-26 21.1-47.1 47.1-47.1 16.7 0 31.4 8.7 39.7 21.8l42.7-27.2A97.63 97.63 0 0 0 268.1 0c-36.5 0-68.3 20.1-85.1 49.7A98 98 0 0 0 97.8 0C43.9 0 0 43.9 0 97.8s43.9 97.8 97.8 97.8c36.5 0 68.3-20.1 85.1-49.7a97.76 97.76 0 0 0 149.6 25.4l19.4 22.2h3v-87.8h-80l24.3 27.5zM97.8 145c-26 0-47.1-21.1-47.1-47.1s21.1-47.1 47.1-47.1 47.2 21 47.2 47S123.8 145 97.8 145"></path></svg><span class="">All content is available under the Open Government Licence v3.0, except where otherwise stated.</span></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"source":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, {})\n  })) : _createMdxContent();\n  function _createMdxContent() {\n    const _components = Object.assign({\n      h2: \"h2\",\n      p: \"p\",\n      a: \"a\",\n      strong: \"strong\",\n      br: \"br\",\n      h3: \"h3\",\n      h4: \"h4\",\n      img: \"img\",\n      ul: \"ul\",\n      li: \"li\",\n      blockquote: \"blockquote\"\n    }, _provideComponents(), props.components), {Tags} = _components;\n    if (!Tags) _missingMdxReference(\"Tags\", true);\n    return _jsxs(_Fragment, {\n      children: [_jsx(Tags, {\n        title: \"\",\n        tags: ['vision AI', 'classification', 'deep learning', 'pathology', 'neural networks']\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"Info\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"This is a backup of the case study published \", _jsx(_components.a, {\n          href: \"https://transform.england.nhs.uk/ai-lab/explore-all-resources/develop-ai/using-deep-learning-to-detect-adrenal-lesions-in-ct-scans/\",\n          children: \"here\"\n        }), \" on the NHS England Transformation Directorate website.\"]\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"Case Study\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Many cases of adrenal lesions, known as adrenal incidentalomas, are discovered incidentally on CT scans performed for other medical conditions. These lesions can be malignant, and so early detection is crucial for patients to receive the correct treatment and allow the public health system to target resources efficiently. Traditionally, the detection of adrenal lesions on CT scans relies on manual analysis by radiologists, which can be time-consuming and unsystematic.\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [_jsx(_components.strong, {\n          children: \"The challenge\"\n        }), _jsx(_components.br, {}), \"\\n\", \"Can applying AI and deep learning augment the detection of adrenal incidentalomas in patients’ CT scans?\"]\n      }), \"\\n\", _jsx(_components.h3, {\n        children: \"Overview\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Autopsy studies reveal a statistic that as many as 6% of all natural deaths displayed a previously undiagnosed adrenal lesion. Such lesions are also found incidentally (and are therefore referred to as adrenal incidentalomas) in approximately 1% of chest or abdominal CT scans. These lesions affect approximately 50,000 patients annually in the United Kingdom, with significant impact on patient health, including 10% to 15% of cases of excess hormone production, or 1% to 5% of cases of cancer.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"It is a significant challenge for the health care system to, in a standardised way, promptly reassure the majority of patients, who have no abnormalities, whilst effectively focusing on those with hormone excess or cancers. Issues include over-reporting (false positives), causing patient anxiety and unnecessary investigations (wasting resources of the health care system), and under-reporting (missed cases), with potentially fatal outcomes. This has major impacts on patient well-being and clinical outcomes, as well as cost-effectiveness.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"The main aim of this study was to examine whether or not using Artificial Intelligence (AI) can improve the detection of adrenal incidentalomas in CT scans. Previous studies have suggested that AI has the potential in distinguishing different types of adrenal lesions. In this study, we specifically focused on detecting the presence of any type of adrenal lesion in CT scans. To demonstrate this proof-of-concept, we investigated the potential of applying deep learning techniques to predict the likelihood of a CT abdominal scan presenting as ‘normal’ or ‘abnormal’, the latter implying the presence of an adrenal lesion.\"\n      }), \"\\n\", _jsx(_components.h3, {\n        children: \"What we did\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Using the data provided by University Hospitals of North Midlands NHS Trust, we developed a 2.5D deep learning model to perform detection of adrenal lesions in patients’ CT scans (binary classification of normal and abnormal adrenal glands). The entire dataset is completely anonymised and does not contain any personal or identifiable information of patients. The only clinical information taken were the binary labels for adrenal lesions (‘normal’ or ‘abnormal’) for the pseudo-labelled patients and their CT scans.\"\n      }), \"\\n\", _jsx(_components.h4, {\n        children: \"2.5D images\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"A 2.5D image is a type of image that lies between a typical 2D and 3D image. It can retain some level of 3D features and can potentially be processed as a 2D image by deep learning models. A greyscale 2D image is two dimensional with a size of x × y, where x and y are the length and width of the 2D image. For a greyscale 3D image (e.g., a CT scan), with a size of x × y × n, it can be considered as a combination of a stack of n number of greyscale 2D images. In other words, a CT scan is a 3D image consisting of multiple 2D images layered on top of each other. The size of a 2.5D image is x × y × 3, and it represents a stack of 3 greyscale 2D images.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Typically, an extra dimension of pixel information is required to record and display 2D colour images in electronic systems, such as the three RGB (red, green, and blue) colour channels. This increases the size of a 2D image to x × y × 3, where the 3 represents the three RGB channels. Many commonly used families of 2D deep learning algorithms (e.g., VGG, ResNet, and EfficientNet) have taken colour images into account and have the ability to process images with the extra three channels. Taking the advantage of the fact that pixel volumes have the same size between 2D colour images and 2.5D images, converting our 3 dimensional CT scan data to 2.5D images can allow us to apply 2D deep learning models on our images.\"\n      }), \"\\n\", _jsx(_components.h4, {\n        children: \"Why using a 2.5D model\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Due to the intrinsic nature of CT scans (e.g., a high operating cost, limited number of available CT scanners, and patients’ exposure to radiation), the acquisition of a sufficient amount of CT scans for 3D deep learning models training is challenging. In many cases, the performance of 3D deep learning models is limited by the small and non-diversified dataset. Training, validating, and testing the model with a small dataset can lead to many disadvantages, for example, a high risk of overfitting the training-validation set (low prediction ability on an unseen test set), and evaluating the model performance within the ambit of a small number statistic (underrepresented test set results in the test accuracy much lower/higher than the underlying model performance).\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"To overcome some of the disadvantage of training a 3D deep learning model, we took a 2.5D deep learning model approach in this case study. Training the model using 2.5D images enables our deep learning model to still learn from the 3D features of the CT scans, while increasing the number of training and testing data points in this study. Moreover, we can apply 2D deep learning models to the set of 2.5D images, which allow us to apply transfer learning to train our own model further based on the knowledge learned by other deep learning applications (e.g., ImageNet, and the NHS AI Lab’s National COVID-19 Chest Imaging Database).\"\n      }), \"\\n\", _jsx(\"figure\", {\n        children: _jsx(_components.p, {\n          children: _jsx(_components.img, {\n            src: \"images/Flow_of_transfer.width-800.png\",\n            alt: \"Adrenal flow of transfer\"\n          })\n        })\n      }), \"\\n\", _jsx(_components.h4, {\n        children: \"Classification of 3D CT scans\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"To perform the binary classification on the overal CT scans (instead of a single 2.5D image), the classification results from each individual 2.5D image that make up a CT scan are considered.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"To connect the classification prediction results from the 2.5D images to the CT scan, we introduce an operating value for our model to provide the final classification. The CT scans are classified as normal if the number of abnormal 2.5D images is lower than the threshold operating value. For example, if the operating value is defined to be X, a CT scan will be considered as normal if there are more than X of its 2.5D images classified as normal by our model.\"\n      }), \"\\n\", _jsx(_components.h4, {\n        children: \"Processing the CT scans to focus on the adrenal glands\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"To prepare the CT scans for this case study (region of interest focus on the adrenal grands), we also developed a manual 3D cropping tool for CT scans. This cropping applied to all three dimensions, including a 1D cropping to select the appropriate axial slices and a 2D cropping on each axial slice. The final cropped 3D image covered the whole adrenal gland on both sides with some extra margin on each side.\"\n      }), \"\\n\", _jsx(\"figure\", {\n        children: _jsx(_components.p, {\n          children: _jsx(_components.img, {\n            src: \"images/Cropping_process.width-800.png\",\n            alt: \"Adrenal cropping\"\n          })\n        })\n      }), \"\\n\", _jsx(_components.h3, {\n        children: \"Outcomes and lessons learned\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [_jsx(_components.a, {\n          href: \"https://github.com/nhsx/skunkworks-adrenal-lesions-detection\",\n          children: \"The resulting code, released as open source on our\"\n        }), \" Github (available to anyone to re-use), enables users to:\"]\n      }), \"\\n\", _jsxs(_components.ul, {\n        children: [\"\\n\", _jsx(_components.li, {\n          children: \"Process CT scans to focus on the region of interest (e.g., adrenal glands),\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Transform 3D CT scans to sets of 2.5D images,\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Train a deep learning model with the 2.5D images for adrenal lesion detection (classification: normal vs. abnormal),\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Evaluate the trained deep learning model on an independent test set.\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"This proof-of-concept model demonstrates the ability and potential of applying such deep learning techniques in the detection of adrenal lesions on CT scans. It also shows an opportunity to detect adrenal incidentalomas using deep learning.\"\n      }), \"\\n\", _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.p, {\n          children: \"An AI solution will allow for lesions to be detected more systematically and flagged for the reporting radiologist. In addition to enhanced patient safety, through minimising missed cases and variability in reporting, this is likely to be a cost-effective solution, saving clinician time.\\n– Professor Fahmy Hanna, Professor of Endocrinology and Metabolism, Keele Medical School and University Hospitals of North Midlands NHS Trust\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsx(_components.h3, {\n        children: \"Who was involved?\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"This project was a collaboration between the NHS AI Lab Skunkworks, within the Transformation Directorate at NHS England and NHS Improvement, and University Hospitals of North Midlands NHS Trust.\"\n      })]\n    });\n  }\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{"title":"Using deep learning to detect adrenal lesions in CT scans","summary":"Augmenting the detection of adrenal incidentalomas in patients’ CT scans.","category":"CaseStudies"}},"meta":{"title":"Using deep learning to detect adrenal lesions in CT scans","summary":"Augmenting the detection of adrenal incidentalomas in patients’ CT scans.","category":"CaseStudies"}},"__N_SSG":true},"page":"/[slug]","query":{"slug":"casestudy-adrenal"},"buildId":"S7_uiDiuluxHyjQ4xYDZ1","assetPrefix":"/skunkworks","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>